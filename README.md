 AI RAG Project

This project contains experiments and development work related to Retrieval-Augmented Generation (RAG) and AI workflows.

---

## ðŸ“¦ Project Structure

AI/
â”œâ”€â”€ notebooks/ # Jupyter notebooks
â”œâ”€â”€ src/ # Python source code
â”œâ”€â”€ .venv/ # Virtual environment (NOT committed)
â”œâ”€â”€ .env # API keys and secrets (NOT committed)
â”œâ”€â”€ .env.example # Template for environment variables
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ README.md

# On terminal
![alt text](image-1.png)

# CTRL (Strg) + SHIFT Button above Strg + E 
Exit extension viewClose specfic extensions
# CTRL (Strg) + SHIFT Button above Strg + F
Close speific extension
 

---

## ðŸ Python Setup

### 1ï¸âƒ£ Check Python Version
python3 --version

---

### 2ï¸âƒ£ Create Virtual Environment
conda deactivate 
This removes base
source .venv/bin/activate
pip freeze 
gives you list of installed packages

pip freeze > requirements-lock.txt
# For reproducibility

---

### 4ï¸âƒ£ Upgrade pip + Install dotenv
pip install -U pip python-dotenv


---

## ðŸ” Environment Variables

Create `.env` file:

nano .env


Example:
OPENAI_API_KEY=
OPENROUTER_API_KEY=
APP_NAME=AI
APP_URL=http://localhost


---

## âš ï¸ Security Rules

Never commit:

.env
.venv/


---

## ðŸ“„ .gitignore
.env
.venv/
pycache/
.ipynb_checkpoints/


---

## ðŸ“¦ Install Dependencies

pip freeze > requirements.txt
pip install -r requirements.txt


---

## â–¶ï¸ Running Python With .env

Example:

from dotenv import load_dotenv
import os

load_dotenv()

print(os.getenv("OPENAI_API_KEY"))


---

## ðŸ’¡ Development Workflow

1. Activate environment
2. Install dependencies
3. Update `.env`
4. Run notebooks / scripts

---



# Desktop to Ubuntu
cd find . -iname "*modi*" | less
find . -iname "*gandhi*" | less
cp "./Papa/Outskill_AIGF_Engineering_Material/Jan30and31/kb_modiji.txt" ~/AI/
python --version
python3 -m venv .venv
source ai_env/bin/activate
which python
# /root/AI/ai_env/bin/python
python --version
# Python 3.11.14
pip install -U pip python-dotenv
# Upgrades to latest vesion
# ðŸ‘‰ Loads environment variables from .env file into Python
AI_RAG_PROJECT/
 â”œâ”€â”€ notebooks/
 â”œâ”€â”€ src/
 â”œâ”€â”€ ai_env/
 â”œâ”€â”€ .env
 â”œâ”€â”€ .env.example
 â”œâ”€â”€ .gitignore
 â”œâ”€â”€ requirements.txt
 â””â”€â”€ README.md


.venv/
 â”œâ”€â”€ python
 â”œâ”€â”€ pip
 â”œâ”€â”€ langchain
 â”œâ”€â”€ openai
 â””â”€â”€ packages

git status -sb
![alt text](image.png)
# main = Currenly on main branch
# m = modified files
# ?? = Untracked files (These are vector databasese)
# Vector databases should not be tracked (Embeddings + Index files + Metadata + Binary Storage)
## Reason: Large, Regeneratable, Machine-specific, May expose API/embedding configs
git add .
git commit -m "Upload complete folder"
git push

# Sync with Windows
rsync -av ~/AI /mnt/c/Users/grove/OneDrive/Desktop/Papa/Outskill_AIGF_Engineering_Material/

# Always add vector database to gitignore after generating new vector databases

RAG Application Dependency Tree
â”œâ”€â”€ numpy (base)
â”œâ”€â”€ pandas (base)
â”œâ”€â”€ scikit-learn (metrics)
â”œâ”€â”€ python-dotenv (config)
â”œâ”€â”€ LangChain Stack
â”‚   â”œâ”€â”€ langchain (core framework)
â”‚   â”œâ”€â”€ langchain-core (abstractions)
â”‚   â”œâ”€â”€ langchain-community (integrations)
â”‚   â”œâ”€â”€ langchain-text-splitters (chunking)
â”‚   â”œâ”€â”€ langchain-openai (GPT models)
â”‚   â”œâ”€â”€ langchain-huggingface (embeddings)
â”‚   â””â”€â”€ langchain-chroma (vector store)
â”œâ”€â”€ Embeddings
â”‚   â”œâ”€â”€ transformers (models)
â”‚   â””â”€â”€ sentence-transformers (sentence embeddings)
â””â”€â”€ Vector Database
    â”œâ”€â”€ chromadb (storage)
    â””â”€â”€ pysqlite3 (Colab fix)

    # https://claude.ai/chat/a70e64d7-089a-49ad-8ada-0b26341e7eb1#python-standard-library



    cp "/mnt/c/Users/grove/Downloads/Packages_Methods.md" ~/AI/
    cp "/mnt/c/Users/grove/Downloads/Installation_guide.md" ~/AI/


project/
â”œâ”€ data_sources.yaml
â”œâ”€ src/
â”‚  â”œâ”€ rag/
â”‚  â”‚  â”œâ”€ pipeline.py          # orchestrates phases
â”‚  â”‚  â”œâ”€ models.py            # Document, Chunk, SourceSpec
â”‚  â”‚  â”œâ”€ registry.py          # maps type -> loader
â”‚  â”‚  â”œâ”€ normalize.py         # normalize_text, clean_html, etc.
â”‚  â”‚  â”œâ”€ chunkers/
â”‚  â”‚  â”‚  â”œâ”€ base.py
â”‚  â”‚  â”‚  â”œâ”€ recursive.py
â”‚  â”‚  â”‚  â”œâ”€ token.py
â”‚  â”‚  â”‚  â”œâ”€ sentence.py
â”‚  â”‚  â”‚  â”œâ”€ paragraph.py
â”‚  â”‚  â”‚  â””â”€ headers.py
â”‚  â”‚  â””â”€ loaders/
â”‚  â”‚     â”œâ”€ base.py
â”‚  â”‚     â”œâ”€ file_text.py      # txt/md
â”‚  â”‚     â”œâ”€ pdf.py            # pdf -> text
â”‚  â”‚     â”œâ”€ docx.py           # docx -> text
â”‚  â”‚     â”œâ”€ html_url.py       # url -> html -> main content
â”‚  â”‚     â”œâ”€ csv.py            # csv -> text rows
â”‚  â”‚     â”œâ”€ json.py           # json -> flattened text
â”‚  â”‚     â””â”€ folder.py         # folder glob expansion into many SourceSpec
â”œâ”€ scripts/
â”‚  â”œâ”€ phase_a_run.py          # CLI runner calling pipeline
â””â”€ outputs/


![alt text](image-6.png)
![alt text](image-5.png)
![alt text](image-4.png)
![alt text](image-3.png)
![](image-2.png)