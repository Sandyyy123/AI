{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f0a8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import load_settings\n",
    "settings = load_settings(\"../.env\")  # since notebook is in /notebooks\n",
    "settings\n",
    "https://chatgpt.com/share/6985199f-9d30-8010-921b-c3fe17cc3a33\n",
    "\n",
    "https://chatgpt.com/c/69850236-54c4-838a-9019-e418c3ce5fc2\n",
    "\n",
    "# Working on the recursive strategy for chunking and embedding. \n",
    "PYTHONPATH=. python scripts/phase_a_build_chunks.py --config-path config.yaml --data-sources-path data_sources.yaml\n",
    "#python scripts/phase_a_build_chunks.py --exclude corpus_pdf corpus_docx dspy_rag_tutorial --strategy recursive\n",
    "\n",
    "#python scripts/phase_b_embed.py   --input outputs/chunks_all_recursive.jsonl   --chroma_mode local   --persist chroma_db_recursive_openai   --collection chunks_recursive_openai   --embedder openai   --model text-embedding-3-small\n",
    "\n",
    "# Need to solve the issue of same vector database name in case of overlapping methods..\n",
    "\n",
    "# Include embedding model and document name in the chunk name. Identify how the chunks are storesd and how to read them and same with embedding.\n",
    "# Check test\n",
    "python -c \"from langchain_text_splitters import RecursiveCharacterTextSplitter, MarkdownHeaderTextSplitter, HTMLSectionSplitter, NLTKTextSplitter; print('splitters ok')\"\n",
    "python -c \"from src.rag.components.chunkers import CHUNK_STRATEGY_REGISTRY; print(CHUNK_STRATEGY_REGISTRY.keys())\"\n",
    "python scripts/phase_a_build_chunks.py --config-path config.yaml --data-sources-path data_sources.yaml\n",
    "\n",
    "# Understnad what is this doing: https://chatgpt.com/c/698a49d9-1eec-838a-aed2-77c5da9249f8\n",
    "touch scripts/__init__.py\n",
    "touch scripts/rag/__init__.py\n",
    "touch scripts/rag/components/__init__.py\n",
    "\n",
    "# Next steps:\n",
    "# Correct python script path issue\n",
    "# Include exclude command in options.\n",
    "# Add filetypes\n",
    "\n",
    "\n",
    "wget -P data/corpus/markdown \\\n",
    "https://raw.githubusercontent.com/langchain-ai/langchain/master/README.md\n",
    "mv data/corpus/markdown/README.md data/corpus/markdown/langchain_readme_overview.md\n",
    "\n",
    "cp \"/mnt/c/Users/grove/Downloads/Ravinder_Singh_Rana_CV_English.docx\" ~/AI/data/corpus/docs\n",
    "\n",
    "cp data/corpus/papers/*.pdf data/corpus/mixed/\n",
    "cp data/corpus/docs/*.docx data/corpus/mixed/\n",
    "cp data/corpus/txt/*.txt data/corpus/mixed/\n",
    "cp data/corpus/markdown/*.md data/corpus/mixed/\n",
    "cp data/corpus/html_archive/*.html data/corpus/mixed/\n",
    "\n",
    "wget -O data/corpus/structured/iris.csv \\\n",
    "https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv\n",
    "\n",
    "cat data/corpus/structured/iris.csv | tr ',' '\\t' > data/corpus/structured/iris.tsv\n",
    "\n",
    "\n",
    "\n",
    "wget -O data/corpus/structured/sample.xlsx \\\n",
    "https://github.com/plotly/datasets/raw/master/2014_usa_states.xlsx\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
